"""
Enhanced Multi-Modal DMAE ä½¿ç”¨ç¤ºä¾‹ - ä¿®å¤ç‰ˆ + è‡ªåŠ¨æ¨¡å‹è¯†åˆ«
å±•ç¤ºå¦‚ä½•ä½¿ç”¨å¢å¼ºå‹å¤šæ¨¡æ€DMAEè¿›è¡Œè®­ç»ƒå’Œæ¨ç†

ä¿®å¤å†…å®¹:
1. âœ… å»¶è¿Ÿåˆå§‹åŒ– StudentModel (ç­‰å¾… num_patches ç¡®å®š)
2. âœ… è‡ªåŠ¨ä»æ•°æ®ä¸­è®¡ç®— num_patches
3. âœ… å…¼å®¹è®­ç»ƒæ¡†æ¶çš„åˆå§‹åŒ–æµç¨‹
4. âœ… å¢å¼ºé”™è¯¯æç¤ºå’Œè°ƒè¯•ä¿¡æ¯
5. âœ… è‡ªåŠ¨è¯†åˆ«å¹¶åŠ è½½ TeacherModel æˆ– StudentModel
6. âœ… æ”¯æŒéƒ¨åˆ†æƒé‡åŠ è½½(strict=False)

ä½¿ç”¨æ–¹æ³•:
1. è®­ç»ƒæ¨¡å‹: python example.py train --dataset_root <path> --dataset_config <config.yaml>
2. æµ‹è¯•æ¨¡å‹: python example.py test --model_path <model.pth> --dataset_root <path> --dataset_config <config.yaml>
3. æ¨ç†å•ä¸ªæ ·æœ¬: python example.py infer --model_path <model.pth> --csi_file <csi.mat>
4. æ¼”ç¤ºæ¨¡å¼: python example.py demo
"""

import os
import sys
import argparse
import yaml
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models import TeacherModel, StudentModel
from data_processing import CSIPreprocessor, SkeletonPreprocessor
from train import EnhancedDMAETrainer, load_config
from utils import (
    load_checkpoint, calculate_skeleton_metrics,
    visualize_skeleton_prediction, print_model_info, get_device
)


class EnhancedDMAEInference:
    """
    å¢å¼ºå‹å¤šæ¨¡æ€DMAEæ¨ç†å™¨ - è‡ªåŠ¨æ¨¡å‹è¯†åˆ«ç‰ˆ

    æ–°å¢åŠŸèƒ½:
    - è‡ªåŠ¨è¯†åˆ« TeacherModel æˆ– StudentModel
    - æ”¯æŒéƒ¨åˆ†æƒé‡åŠ è½½(strict=False)
    - å®Œæ•´çš„åŠ è½½æŠ¥å‘Šè¾“å‡º
    """

    def __init__(self, model_path, config_path=None, num_patches=None, patch_dim=None):
        """
        Args:
            model_path: æ¨¡å‹è·¯å¾„
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            num_patches: å¯é€‰,æå‰ä¼ å…¥çš„num_patches,é¿å…é‡å¤è®¡ç®—
            patch_dim: å¯é€‰,æå‰ä¼ å…¥çš„patch_dim,é¿å…é‡å¤è®¡ç®—
        """
        self.device = get_device()
        self.model_path = model_path
        self.model_type = None  # 'teacher' æˆ– 'student'
        self.model = None

        # åŠ è½½é…ç½®
        if config_path and os.path.exists(config_path):
            self.config = load_config(config_path)
        else:
            self.config = self.get_default_inference_config()

        # åˆå§‹åŒ–é¢„å¤„ç†å™¨
        self.csi_preprocessor = CSIPreprocessor(**self.config['csi_preprocessor'])
        self.skeleton_preprocessor = SkeletonPreprocessor(**self.config['skeleton_preprocessor'])

        # æ¨¡å‹åˆå§‹åŒ–çŠ¶æ€
        self._model_initialized = False
        self._num_patches_determined = False

        # å¦‚æœæå‰ç»™å®š num_patches å’Œ patch_dim,ç›´æ¥ä½¿ç”¨
        if num_patches is not None and patch_dim is not None:
            self.num_patches = num_patches
            self.patch_dim = patch_dim
            self._num_patches_determined = True
        else:
            self.num_patches = None
            self.patch_dim = None

        # è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹
        self._detect_model_type()

        print("âœ… æ¨ç†å™¨åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åŠ è½½)")

    def _detect_model_type(self):
        """è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹"""
        model_path_lower = self.model_path.lower()

        if 'teacher' in model_path_lower:
            self.model_type = 'teacher'
            print("âœ… æ£€æµ‹åˆ° Teacher æ¨¡å‹")
        else:
            self.model_type = 'student'
            print("âœ… æ£€æµ‹åˆ° Student æ¨¡å‹")

    def get_default_inference_config(self):
        """è·å–é»˜è®¤æ¨ç†é…ç½®"""
        print("âš ï¸  æœªæä¾› --config å‚æ•°, æ­£åœ¨ä½¿ç”¨ example.py ä¸­çš„é»˜è®¤é…ç½®...")
        return {
            'csi_preprocessor': {
                'num_antennas': 3,
                'num_subcarriers': 114,
                'time_length': 10,
                'stft_window': 64,
                'stft_hop': 16,
                'patch_size': 8,
                'normalize': True
            },
            'skeleton_preprocessor': {
                'num_joints': 17,
                'coord_dim': 2,
                'normalize': True
            },
            'teacher_model': {
                'embed_dim': 768,
                'depth': 12,
                'num_heads': 12,
                'decoder_embed_dim': 512,
                'decoder_depth': 8,
                'decoder_num_heads': 16,
                'num_joints': 17,
                'coord_dim': 2,
                'mask_ratio': 0.75
            },
            'student_model': {
                'embed_dim': 768,
                'depth': 12,
                'num_heads': 12,
                'decoder_embed_dim': 512,
                'decoder_depth': 8,
                'decoder_num_heads': 16,
                'num_joints': 17,
                'coord_dim': 2,
                'contrast_dim': 128,
                'mask_ratio': 0.75,
                'num_antennas': 3,
                'use_multi_attn': True
            }
        }

    def _load_model_auto(self):
        """è‡ªåŠ¨åŠ è½½æ¨¡å‹æƒé‡"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")

        print("\n" + "=" * 60)
        print("ğŸ”§ æ­£åœ¨åŠ è½½æ¨¡å‹æƒé‡...")
        print("=" * 60)

        # åŠ è½½checkpoint
        checkpoint = torch.load(self.model_path, map_location=self.device)

        # æå–state_dict
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        else:
            state_dict = checkpoint

        # å°è¯•ä¸¥æ ¼åŠ è½½
        try:
            self.model.load_state_dict(state_dict, strict=True)
            load_info = {'missing_keys': [], 'unexpected_keys': []}
            loaded_percent = 100.0
            skipped_layers = 0
        except RuntimeError as e:
            # å¦‚æœä¸¥æ ¼åŠ è½½å¤±è´¥,ä½¿ç”¨éä¸¥æ ¼æ¨¡å¼
            print(f"âš ï¸  ä¸¥æ ¼åŠ è½½å¤±è´¥,åˆ‡æ¢åˆ° strict=False æ¨¡å¼")
            load_info = self.model.load_state_dict(state_dict, strict=False)

            # è®¡ç®—åŠ è½½æ¯”ä¾‹
            total_params = len(self.model.state_dict())
            missing_params = len(load_info.get('missing_keys', []))
            unexpected_params = len(load_info.get('unexpected_keys', []))
            skipped_layers = missing_params + unexpected_params
            loaded_percent = ((total_params - missing_params) / total_params) * 100 if total_params > 0 else 0.0

            # æ‰“å°è­¦å‘Š
            if missing_params > 0:
                print(f"âš ï¸  æƒé‡éƒ¨åˆ†ä¸åŒ¹é…,å·²è·³è¿‡ {skipped_layers} å±‚:")
                print(f"   ç¼ºå¤±çš„é”® ({missing_params}): {load_info['missing_keys'][:5]}...")
            if unexpected_params > 0:
                print(f"   æ„å¤–çš„é”® ({unexpected_params}): {load_info['unexpected_keys'][:5]}...")

        self.model.eval()

        # æ‰“å°åŠ è½½æŠ¥å‘Š
        print("\n" + "=" * 60)
        print("ğŸ§© æ¨¡å‹åŠ è½½æŠ¥å‘Š")
        print("=" * 60)
        print(f"ç±»å‹: {self.model.__class__.__name__}")
        print(f"è·¯å¾„: {self.model_path}")

        total_params = sum(p.numel() for p in self.model.parameters())
        print(f"æ€»å‚æ•°: {total_params:,}")
        print(f"å·²åŠ è½½: {loaded_percent:.1f}%")
        print(f"è·³è¿‡å±‚æ•°: {skipped_layers}")
        print("=" * 60 + "\n")

        if loaded_percent < 50:
            print("âš ï¸  è­¦å‘Š: åŠ è½½çš„å‚æ•°æ¯”ä¾‹è¿‡ä½,æ¨¡å‹å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")

    def _ensure_model_initialized(self, sample_csi_data=None):
        """ç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–"""
        if self._model_initialized:
            return

        print("\n" + "=" * 60)
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
        print("=" * 60)

        if self.model_type == 'teacher':
            # æ•™å¸ˆæ¨¡å‹ç›´æ¥åˆå§‹åŒ–
            self._initialize_teacher_model()
        else:
            # å­¦ç”Ÿæ¨¡å‹éœ€è¦ç¡®å®š num_patches
            self._initialize_student_model(sample_csi_data)

        # åŠ è½½æƒé‡
        self._load_model_auto()

        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        model_name = "Teacher Model" if self.model_type == 'teacher' else "Student Model"
        print_model_info(self.model, f"{model_name} (Inference)")

        self._model_initialized = True
        print("=" * 60)
        print("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\n")

    def _initialize_teacher_model(self):
        """åˆå§‹åŒ–æ•™å¸ˆæ¨¡å‹"""
        try:
            self.model = TeacherModel(
                **self.config['teacher_model']
            ).to(self.device)
            print("âœ… æ•™å¸ˆæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            raise RuntimeError(f"åˆ›å»ºæ•™å¸ˆæ¨¡å‹å¤±è´¥: {e}") from e

    def _initialize_student_model(self, sample_csi_data):
        """åˆå§‹åŒ–å­¦ç”Ÿæ¨¡å‹"""
        # æ­¥éª¤1: ç¡®å®š num_patches
        if not self._num_patches_determined:
            if sample_csi_data is None:
                raise RuntimeError(
                    "å­¦ç”Ÿæ¨¡å‹éœ€è¦æ ·æœ¬æ•°æ®æ¥ç¡®å®š num_patches,ä½†æœªæä¾› sample_csi_data"
                )

            try:
                # ç¡®ä¿æ˜¯4ç»´å¼ é‡
                if len(sample_csi_data.shape) == 3:
                    sample_csi_data = sample_csi_data.unsqueeze(0)

                # æ£€æŸ¥æ•°æ®æ ¼å¼å¹¶è½¬æ¢
                if sample_csi_data.shape[-1] == self.csi_preprocessor.num_antennas:
                    print(f"   æ£€æµ‹åˆ°MMFiæ ¼å¼ [B, F, T, A]: {sample_csi_data.shape}")
                    print("   ...æ­£åœ¨è½¬æ¢ä¸º [B, A, F, T]")
                    sample_csi_data = sample_csi_data.permute(0, 3, 1, 2)
                else:
                    print(f"   å‡è®¾è¾“å…¥å·²æ˜¯ [B, A, F, T] æ ¼å¼: {sample_csi_data.shape}")

                print(f"   ç”¨äºåˆå§‹åŒ–çš„æ ·æœ¬CSIå½¢çŠ¶: {sample_csi_data.shape}")

                # è¿è¡Œé¢„å¤„ç†å™¨
                with torch.no_grad():
                    patches, _ = self.csi_preprocessor(sample_csi_data)

                self.num_patches = self.csi_preprocessor.num_patches
                self.patch_dim = self.csi_preprocessor.patch_dim

                if self.num_patches is None:
                    raise RuntimeError(
                        "CSIé¢„å¤„ç†å™¨æœªèƒ½ç¡®å®š num_patches!\n"
                        f"Patches shape: {patches.shape}\n"
                        f"è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®, ä»¥åŠ csi_preprocessor é…ç½®æ˜¯å¦ä¸è®­ç»ƒæ—¶ä¸€è‡´"
                    )

                print(f"   âœ… num_patches å·²ç¡®å®š: {self.num_patches}")
                print(f"   âœ… patch_dim å·²ç¡®å®š: {self.patch_dim}")

            except Exception as e:
                raise RuntimeError(
                    f"ç¡®å®š num_patches å¤±è´¥: {e}\n"
                    "å¯èƒ½çš„åŸå› :\n"
                    "1. CSIæ•°æ®æ ¼å¼ä¸æ­£ç¡®\n"
                    "2. é¢„å¤„ç†å™¨é…ç½®å‚æ•°é”™è¯¯ (get_default_inference_config)\n"
                    "3. æ•°æ®ç»´åº¦ä¸é…ç½®ä¸åŒ¹é…"
                ) from e

            self._num_patches_determined = True

        # æ­¥éª¤2: åˆ›å»ºå­¦ç”Ÿæ¨¡å‹
        try:
            self.model = StudentModel(
                num_patches=self.num_patches,
                patch_dim=self.patch_dim,
                **self.config['student_model']
            ).to(self.device)
            print("âœ… å­¦ç”Ÿæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            raise RuntimeError(f"åˆ›å»ºå­¦ç”Ÿæ¨¡å‹å¤±è´¥: {e}") from e

    def predict_skeleton(self, csi_data):
        """
        ä»CSIæ•°æ®é¢„æµ‹éª¨éª¼ç‚¹

        Args:
            csi_data: CSIæ•°æ® [batch, freq, time, antennas] (MMFiæ ¼å¼) æˆ–
                     [freq, time, antennas] (å•æ ·æœ¬) æˆ–
                     [batch, antennas, subcarriers, time] (æ ‡å‡†æ ¼å¼)

        Returns:
            skeleton: é¢„æµ‹çš„éª¨éª¼ç‚¹ [batch, num_joints, coord_dim] æˆ– [num_joints, coord_dim]
        """
        # å¦‚æœæ˜¯æ•™å¸ˆæ¨¡å‹,ç»™å‡ºæç¤º
        if self.model_type == 'teacher':
            print("âš ï¸  å½“å‰ä¸ºæ•™å¸ˆæ¨¡å‹,ä»…æ”¯æŒè¾“å…¥éª¨éª¼æ•°æ®ã€‚")
            print("   å°†è·³è¿‡CSIé¢„å¤„ç†,å‡è®¾è¾“å…¥ä¸ºéª¨éª¼æ•°æ®...")

            # ç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–
            if not self._model_initialized:
                self._ensure_model_initialized()

            # æ•™å¸ˆæ¨¡å‹ç›´æ¥å¤„ç†éª¨éª¼æ•°æ®
            if not isinstance(csi_data, torch.Tensor):
                csi_data = torch.tensor(csi_data, dtype=torch.float32)
            csi_data = csi_data.to(self.device)

            with torch.no_grad():
                _, skeleton_pred, _ = self.model(csi_data)

            return skeleton_pred.cpu()

        # å­¦ç”Ÿæ¨¡å‹å¤„ç†CSIæ•°æ®
        # ç¡®ä¿è¾“å…¥æ˜¯4ç»´çš„
        if len(csi_data.shape) == 3:
            csi_data = csi_data.unsqueeze(0)
            single_sample = True
        else:
            single_sample = False

        # è½¬æ¢ä¸ºtensorå¹¶ç§»åŠ¨åˆ°è®¾å¤‡
        if not isinstance(csi_data, torch.Tensor):
            csi_data = torch.tensor(csi_data, dtype=torch.float32)
        csi_data = csi_data.to(self.device)

        # ç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–
        self._ensure_model_initialized(csi_data[:1])

        with torch.no_grad():
            # æ£€æŸ¥æ•°æ®æ ¼å¼å¹¶è½¬æ¢
            if (csi_data.shape[-1] == self.csi_preprocessor.num_antennas and
                    csi_data.shape[1] != self.csi_preprocessor.num_antennas):
                csi_data = csi_data.permute(0, 3, 1, 2)

            # é¢„å¤„ç†CSIæ•°æ®
            csi_patches, _ = self.csi_preprocessor(csi_data)

            # å­¦ç”Ÿæ¨¡å‹æ¨ç†(ä¸ä½¿ç”¨æ©ç )
            outputs = self.model(csi_patches, mask_ratio=0.0)
            skeleton_pred = outputs['skeleton_pred']

            # å¦‚æœè¾“å…¥æ˜¯å•ä¸ªæ ·æœ¬,ç§»é™¤batchç»´åº¦
            if single_sample:
                skeleton_pred = skeleton_pred.squeeze(0)

        return skeleton_pred.cpu()

    def predict_with_confidence(self, csi_data, num_samples=10):
        """
        ä½¿ç”¨è’™ç‰¹å¡æ´›dropoutä¼°è®¡é¢„æµ‹ç½®ä¿¡åº¦

        Args:
            csi_data: CSIæ•°æ®
            num_samples: é‡‡æ ·æ¬¡æ•°

        Returns:
            mean_skeleton: å¹³å‡é¢„æµ‹éª¨éª¼ç‚¹
            std_skeleton: æ ‡å‡†å·®(ç½®ä¿¡åº¦æŒ‡æ ‡)
        """
        # å¯ç”¨dropoutè¿›è¡Œè’™ç‰¹å¡æ´›é‡‡æ ·
        self.model.train()

        predictions = []
        for _ in range(num_samples):
            pred = self.predict_skeleton(csi_data)
            predictions.append(pred)

        # æ¢å¤è¯„ä¼°æ¨¡å¼
        self.model.eval()

        # è®¡ç®—ç»Ÿè®¡é‡
        predictions = torch.stack(predictions)
        mean_skeleton = predictions.mean(dim=0)
        std_skeleton = predictions.std(dim=0)

        return mean_skeleton, std_skeleton


def train_model(args):
    """è®­ç»ƒæ¨¡å‹"""
    print("=" * 60)
    print("å¼€å§‹è®­ç»ƒEnhanced Multi-Modal DMAE")
    print("=" * 60)

    # åŠ è½½é…ç½®
    if os.path.exists(args.config):
        config = load_config(args.config)
    else:
        print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config},ä½¿ç”¨é»˜è®¤é…ç½®")
        from train import get_default_config
        config = get_default_config()

    # æ›´æ–°è¾“å‡ºç›®å½•
    if args.output_dir:
        config['output_dir'] = args.output_dir

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = EnhancedDMAETrainer(config)

    # å¼€å§‹è®­ç»ƒ
    trainer.train(args.dataset_root, args.dataset_config)


def test_model(args):
    """
    æµ‹è¯•æ¨¡å‹ - ä¿®å¤ç‰ˆ

    ä¿®å¤å†…å®¹:
    - âœ… ä¿®å¤: å¯¹ target_skeleton (çœŸå®æ•°æ®) åº”ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„å½’ä¸€åŒ–
    - è‡ªåŠ¨å¤„ç† num_patches åˆå§‹åŒ–
    - å¢å¼ºé”™è¯¯æç¤º
    - å…¼å®¹ä¸åŒæ•°æ®æ ¼å¼
    """
    print("=" * 60)
    print("æµ‹è¯•Enhanced Multi-Modal DMAE")
    print("=" * 60)

    # åˆ›å»ºæ¨ç†å™¨ (æ¨¡å‹å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åˆå§‹åŒ–)
    try:
        inference = EnhancedDMAEInference(args.model_path, args.config)
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ¨ç†å™¨å¤±è´¥: {e}")
        return

    # åŠ è½½æµ‹è¯•æ•°æ®
    try:
        from mmfi_dataloader import create_enhanced_mmfi_dataloaders

        test_config_path = args.test_config or args.dataset_config
        _, test_loader = create_enhanced_mmfi_dataloaders(
            args.dataset_root, test_config_path, batch_size=1
        )

        print(f"âœ… æµ‹è¯•æ•°æ®å·²åŠ è½½: {len(test_loader)} ä¸ªæ‰¹æ¬¡")

    except Exception as e:
        print(f"âŒ åŠ è½½æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
        return

    # æµ‹è¯•å¾ªç¯
    all_pred_skeletons = []
    all_target_skeletons = []

    print("\næ­£åœ¨è¿›è¡Œæ¨¡å‹æµ‹è¯•...")

    try:
        for batch_idx, batch in enumerate(test_loader):
            if batch_idx >= 100:  # é™åˆ¶æµ‹è¯•æ ·æœ¬æ•°é‡
                break

            if batch_idx == 0:
                print(f"   ç¬¬ä¸€ä¸ªæ‰¹æ¬¡ - CSIå½¢çŠ¶: {batch['csi_data'].shape}")

            csi_data = batch['csi_data']
            target_skeleton_raw = batch['rgb_skeleton']
            target_skeleton_normalized = inference.skeleton_preprocessor(target_skeleton_raw)

            # é¢„æµ‹ (é¦–æ¬¡è°ƒç”¨ä¼šè‡ªåŠ¨åˆå§‹åŒ–æ¨¡å‹)
            try:
                pred_skeleton = inference.predict_skeleton(csi_data)
            except Exception as e:
                print(f"âŒ é¢„æµ‹å¤±è´¥ (batch {batch_idx}): {e}")
                continue

            all_pred_skeletons.append(pred_skeleton)
            all_target_skeletons.append(target_skeleton_normalized)

            if (batch_idx + 1) % 20 == 0:
                print(f"   å·²å¤„ç†: {batch_idx + 1}/{min(100, len(test_loader))} ä¸ªæ‰¹æ¬¡")

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return

    if not all_pred_skeletons:
        print("âŒ æ²¡æœ‰æˆåŠŸé¢„æµ‹ä»»ä½•æ ·æœ¬")
        return

    # è®¡ç®—æŒ‡æ ‡
    try:
        pred_skeletons = torch.cat(all_pred_skeletons, dim=0)
        target_skeletons = torch.cat(all_target_skeletons, dim=0)

        metrics = calculate_skeleton_metrics(pred_skeletons, target_skeletons)

        print("\n=== æµ‹è¯•ç»“æœ ===")
        print(f"MPJPE: {metrics['MPJPE']:.4f}")
        for key, value in metrics.items():
            if key.startswith('PCK'):
                print(f"{key}: {value:.4f}")

    except Exception as e:
        print(f"âŒ è®¡ç®—æŒ‡æ ‡å¤±è´¥: {e}")
        return

    # å¯è§†åŒ–å‡ ä¸ªæ ·æœ¬
    output_dir = args.output_dir or "./test_results"
    os.makedirs(output_dir, exist_ok=True)

    try:
        for i in range(min(5, len(pred_skeletons))):
            vis_path = os.path.join(output_dir, f"test_sample_{i}.png")
            visualize_skeleton_prediction(
                pred_skeletons[i], target_skeletons[i], vis_path
            )

        print(f"âœ… æµ‹è¯•å®Œæˆ,ç»“æœä¿å­˜åˆ°: {output_dir}")

    except Exception as e:
        print(f"âš ï¸ å¯è§†åŒ–å¤±è´¥: {e}")


def infer_single(args):
    """
    æ¨ç†å•ä¸ªæ ·æœ¬ - ä¿®å¤ç‰ˆ
    """
    print("=" * 60)
    print("å•æ ·æœ¬æ¨ç†")
    print("=" * 60)

    # åˆ›å»ºæ¨ç†å™¨
    try:
        inference = EnhancedDMAEInference(args.model_path, args.config)
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ¨ç†å™¨å¤±è´¥: {e}")
        return

    # åŠ è½½CSIæ•°æ®
    try:
        if args.csi_file.endswith('.mat'):
            import scipy.io as scio
            csi_data = scio.loadmat(args.csi_file)['CSIamp']
        elif args.csi_file.endswith('.npy'):
            csi_data = np.load(args.csi_file)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {args.csi_file}")

        print(f"CSIæ•°æ®å½¢çŠ¶: {csi_data.shape}")

    except Exception as e:
        print(f"âŒ åŠ è½½CSIæ•°æ®å¤±è´¥: {e}")
        return

    # é¢„æµ‹éª¨éª¼ç‚¹
    try:
        pred_skeleton = inference.predict_skeleton(csi_data)
        print(f"âœ… é¢„æµ‹éª¨éª¼ç‚¹å½¢çŠ¶: {pred_skeleton.shape}")

    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # å¯è§†åŒ–ç»“æœ
    output_dir = args.output_dir or "./inference_results"
    os.makedirs(output_dir, exist_ok=True)

    vis_path = os.path.join(output_dir, "inference_result.png")

    try:
        # åˆ›å»ºç®€å•çš„å¯è§†åŒ–
        plt.figure(figsize=(8, 6))
        skeleton = pred_skeleton.numpy()
        plt.scatter(skeleton[:, 0], skeleton[:, 1], c='red', s=50, alpha=0.7)

        # æ·»åŠ å…³èŠ‚è¿æ¥
        joint_connections = [
            (0, 1), (0, 2), (1, 3), (2, 4),  # å¤´éƒ¨
            (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # ä¸Šèº«
            (5, 11), (6, 12), (11, 12),  # èº¯å¹²
            (11, 13), (13, 15), (12, 14), (14, 16)  # ä¸‹èº«
        ]

        for connection in joint_connections:
            if connection[0] < len(skeleton) and connection[1] < len(skeleton):
                x_coords = [skeleton[connection[0], 0], skeleton[connection[1], 0]]
                y_coords = [skeleton[connection[0], 1], skeleton[connection[1], 1]]
                plt.plot(x_coords, y_coords, 'r-', alpha=0.5)

        plt.title('Predicted Skeleton from CSI')
        plt.xlabel('X')
        plt.ylabel('Y')
        plt.grid(True, alpha=0.3)
        plt.gca().invert_yaxis()
        plt.savefig(vis_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… æ¨ç†å®Œæˆ,ç»“æœä¿å­˜åˆ°: {vis_path}")

    except Exception as e:
        print(f"âš ï¸ å¯è§†åŒ–å¤±è´¥: {e}")

    # ä¿å­˜é¢„æµ‹ç»“æœ
    try:
        result_path = os.path.join(output_dir, "predicted_skeleton.npy")
        np.save(result_path, pred_skeleton.numpy())
        print(f"âœ… é¢„æµ‹éª¨éª¼ç‚¹ä¿å­˜åˆ°: {result_path}")

    except Exception as e:
        print(f"âš ï¸ ä¿å­˜å¤±è´¥: {e}")


def demo():
    """
    æ¼”ç¤ºæ¨¡å¼ - ä¿®å¤ç‰ˆ

    å±•ç¤ºå»¶è¿Ÿåˆå§‹åŒ–çš„å·¥ä½œæµç¨‹
    """
    print("=" * 60)
    print("Enhanced Multi-Modal DMAE æ¼”ç¤º")
    print("=" * 60)

    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    print("\nåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®...")

    # æ¨¡æ‹ŸCSIæ•°æ®
    batch_size = 4
    num_antennas = 3
    num_subcarriers = 30
    time_length = 297

    csi_data = torch.randn(batch_size, num_antennas, num_subcarriers, time_length)
    print(f"æ¨¡æ‹ŸCSIæ•°æ®å½¢çŠ¶: {csi_data.shape}")

    # æ¨¡æ‹ŸRGBéª¨éª¼ç‚¹æ•°æ®
    rgb_skeleton = torch.randn(batch_size, 17, 2) * 100  # æ¨¡æ‹Ÿåƒç´ åæ ‡
    print(f"æ¨¡æ‹ŸRGBéª¨éª¼ç‚¹å½¢çŠ¶: {rgb_skeleton.shape}")

    # æµ‹è¯•æ•°æ®é¢„å¤„ç†
    print("\næµ‹è¯•æ•°æ®é¢„å¤„ç†...")
    from data_processing import CSIPreprocessor, SkeletonPreprocessor

    csi_preprocessor = CSIPreprocessor()
    skeleton_preprocessor = SkeletonPreprocessor()

    csi_patches, csi_spectrogram = csi_preprocessor(csi_data)
    processed_skeleton = skeleton_preprocessor(rgb_skeleton)

    print(f"CSIè¡¥ä¸å½¢çŠ¶: {csi_patches.shape}")
    print(f"CSIæ—¶é¢‘è°±å½¢çŠ¶: {csi_spectrogram.shape}")
    print(f"å¤„ç†åéª¨éª¼ç‚¹å½¢çŠ¶: {processed_skeleton.shape}")
    print(f"âœ… num_patches å·²ç¡®å®š: {csi_preprocessor.num_patches}")

    # æµ‹è¯•æ¨¡å‹ (ä½¿ç”¨ç¡®å®šçš„ num_patches)
    print("\næµ‹è¯•æ¨¡å‹...")
    from models import TeacherModel, StudentModel

    # âœ… å…³é”®: ä½¿ç”¨å·²ç¡®å®šçš„ num_patches åˆ›å»ºæ¨¡å‹
    teacher_model = TeacherModel(embed_dim=384, depth=6)
    student_model = StudentModel(
        num_patches=csi_preprocessor.num_patches,
        patch_dim=csi_preprocessor.patch_dim,
        embed_dim=384,
        depth=6,
        num_antennas=num_antennas,
        use_multi_attn=True
    )

    print_model_info(teacher_model, "Teacher Model")
    print_model_info(student_model, "Student Model")

    # æ•™å¸ˆæ¨¡å‹å‰å‘ä¼ æ’­
    teacher_loss, teacher_pred, teacher_mask = teacher_model(processed_skeleton)
    print(f"\næ•™å¸ˆæ¨¡å‹æŸå¤±: {teacher_loss.item():.4f}")

    # å­¦ç”Ÿæ¨¡å‹å‰å‘ä¼ æ’­
    student_outputs = student_model(csi_patches)
    print(f"å­¦ç”Ÿæ¨¡å‹è¾“å‡ºé”®: {list(student_outputs.keys())}")
    print(f"é¢„æµ‹éª¨éª¼ç‚¹å½¢çŠ¶: {student_outputs['skeleton_pred'].shape}")

    # æµ‹è¯•æŸå¤±å‡½æ•°
    print("\næµ‹è¯•æŸå¤±å‡½æ•°...")
    from losses import CombinedLoss

    loss_fn = CombinedLoss(
        mae_weight=1.0,
        distill_weight=1.0,
        contrast_weight=0.5
    )

    # æ¨¡æ‹Ÿæ•™å¸ˆç‰¹å¾
    teacher_features = teacher_model.forward_features(processed_skeleton, mask_ratio=0.0)

    # è®¡ç®—ç»„åˆæŸå¤±
    total_loss, loss_dict = loss_fn(
        student_outputs['reconstructed_patches'], csi_patches, student_outputs['mask'],
        student_outputs['skeleton_pred'], processed_skeleton,
        student_outputs['distill_features'], teacher_features,
        student_outputs['contrast_features'][:2],  # anchor
        student_outputs['contrast_features'][2:],  # positive
        torch.randint(0, 2, (2,))  # éšæœºæ ‡ç­¾
    )

    print(f"æ€»æŸå¤±: {total_loss.item():.4f}")
    print("å„é¡¹æŸå¤±:")
    for key, value in loss_dict.items():
        print(f"  {key}: {value.item():.4f}")

    print("\nâœ… æ¼”ç¤ºå®Œæˆ:æ‰€æœ‰ç»„ä»¶å·¥ä½œæ­£å¸¸ã€‚")
    print("\nå…³é”®ç‚¹æ€»ç»“:")
    print("1. âœ… CSIé¢„å¤„ç†å™¨è‡ªåŠ¨è®¡ç®— num_patches")
    print("2. âœ… ä½¿ç”¨ç¡®å®šçš„ num_patches åˆ›å»º StudentModel")
    print("3. âœ… æ¨¡å‹å‰å‘ä¼ æ’­æ­£å¸¸")
    print("4. âœ… æŸå¤±è®¡ç®—æ­£å¸¸")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Enhanced Multi-Modal DMAE Example")
    subparsers = parser.add_subparsers(dest='command', help='å‘½ä»¤')

    # è®­ç»ƒå‘½ä»¤
    train_parser = subparsers.add_parser('train', help='è®­ç»ƒæ¨¡å‹')
    train_parser.add_argument('--dataset_root', type=str, required=True, help='MMFiæ•°æ®é›†æ ¹ç›®å½•')
    train_parser.add_argument('--dataset_config', type=str, required=True, help='æ•°æ®é›†é…ç½®æ–‡ä»¶')
    train_parser.add_argument('--config', type=str, default='config.yaml', help='è®­ç»ƒé…ç½®æ–‡ä»¶')
    train_parser.add_argument('--output_dir', type=str, help='è¾“å‡ºç›®å½•')

    # æµ‹è¯•å‘½ä»¤
    test_parser = subparsers.add_parser('test', help='æµ‹è¯•æ¨¡å‹')
    test_parser.add_argument('--model_path', type=str, required=True, help='æ¨¡å‹è·¯å¾„')
    test_parser.add_argument('--dataset_root', type=str, required=True, help='æµ‹è¯•æ•°æ®é›†æ ¹ç›®å½•')
    test_parser.add_argument('--dataset_config', type=str, required=True, help='æ•°æ®é›†é…ç½®æ–‡ä»¶')
    test_parser.add_argument('--config', type=str, help='æ¨¡å‹é…ç½®æ–‡ä»¶')
    test_parser.add_argument('--test_config', type=str, help='æµ‹è¯•é…ç½®æ–‡ä»¶')
    test_parser.add_argument('--output_dir', type=str, help='è¾“å‡ºç›®å½•')

    # æ¨ç†å‘½ä»¤
    infer_parser = subparsers.add_parser('infer', help='æ¨ç†å•ä¸ªæ ·æœ¬')
    infer_parser.add_argument('--model_path', type=str, required=True, help='æ¨¡å‹è·¯å¾„')
    infer_parser.add_argument('--csi_file', type=str, required=True, help='CSIæ•°æ®æ–‡ä»¶')
    infer_parser.add_argument('--config', type=str, help='æ¨¡å‹é…ç½®æ–‡ä»¶')
    infer_parser.add_argument('--output_dir', type=str, help='è¾“å‡ºç›®å½•')

    # æ¼”ç¤ºå‘½ä»¤
    demo_parser = subparsers.add_parser('demo', help='æ¼”ç¤ºæ¨¡å¼')

    args = parser.parse_args()

    if args.command == 'train':
        train_model(args)
    elif args.command == 'test':
        test_model(args)
    elif args.command == 'infer':
        infer_single(args)
    elif args.command == 'demo':
        demo()
    else:
        parser.print_help()


if __name__ == "__main__":
    main()