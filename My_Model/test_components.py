"""
Enhanced Multi-Modal DMAE ç»„ä»¶æµ‹è¯•è„šæœ¬
æµ‹è¯•æ‰€æœ‰æ¨¡å—æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import torch
import numpy as np
import sys
import os

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_data_processing():
    """æµ‹è¯•æ•°æ®é¢„å¤„ç†æ¨¡å—"""
    print("=" * 50)
    print("æµ‹è¯•æ•°æ®é¢„å¤„ç†æ¨¡å—")
    print("=" * 50)
    
    from data_processing import CSIPreprocessor, SkeletonPreprocessor
    
    # æµ‹è¯•CSIé¢„å¤„ç†å™¨
    print("æµ‹è¯•CSIé¢„å¤„ç†å™¨...")
    csi_preprocessor = CSIPreprocessor(
        num_antennas=3,
        num_subcarriers=30,
        time_length=297,
        patch_size=8
    )
    
    # åˆ›å»ºæ¨¡æ‹ŸCSIæ•°æ®
    batch_size = 2
    csi_data = torch.randn(batch_size, 3, 30, 297)
    
    patches, spectrogram = csi_preprocessor(csi_data)
    print(f"âœ… CSIé¢„å¤„ç†æˆåŠŸ: {csi_data.shape} -> {patches.shape}")
    
    # æµ‹è¯•éª¨éª¼ç‚¹é¢„å¤„ç†å™¨
    print("æµ‹è¯•éª¨éª¼ç‚¹é¢„å¤„ç†å™¨...")
    skeleton_preprocessor = SkeletonPreprocessor(num_joints=17, coord_dim=2)
    
    skeleton_data = torch.randn(batch_size, 17, 2) * 100
    processed_skeleton = skeleton_preprocessor(skeleton_data)
    print(f"âœ… éª¨éª¼ç‚¹é¢„å¤„ç†æˆåŠŸ: {skeleton_data.shape} -> {processed_skeleton.shape}")
    
    return csi_preprocessor, skeleton_preprocessor


def test_models(csi_preprocessor):
    """æµ‹è¯•æ¨¡å‹"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ¨¡å‹")
    print("=" * 50)
    
    from models import TeacherModel, StudentModel
    
    # æµ‹è¯•è€å¸ˆæ¨¡å‹
    print("æµ‹è¯•è€å¸ˆæ¨¡å‹...")
    teacher_model = TeacherModel(
        num_joints=17,
        coord_dim=2,
        embed_dim=384,
        depth=6,
        num_heads=6
    )
    
    batch_size = 2
    skeleton_input = torch.randn(batch_size, 17, 2)
    
    # æµ‹è¯•é¢„è®­ç»ƒæ¨¡å¼
    loss, pred, mask = teacher_model(skeleton_input)
    print(f"âœ… è€å¸ˆæ¨¡å‹é¢„è®­ç»ƒ: æŸå¤±={loss.item():.4f}")
    
    # æµ‹è¯•ç‰¹å¾æå–æ¨¡å¼
    features = teacher_model.forward_features(skeleton_input, mask_ratio=0.0)
    print(f"âœ… è€å¸ˆæ¨¡å‹ç‰¹å¾æå–: {len(features)}å±‚ç‰¹å¾")
    
    # æµ‹è¯•å­¦ç”Ÿæ¨¡å‹
    print("æµ‹è¯•å­¦ç”Ÿæ¨¡å‹...")
    student_model = StudentModel(
        num_patches=csi_preprocessor.num_patches,
        patch_dim=csi_preprocessor.patch_dim,
        embed_dim=384,
        depth=6,
        num_heads=6,
        num_joints=17,
        coord_dim=2
    )
    
    csi_patches = torch.randn(batch_size, csi_preprocessor.num_patches, csi_preprocessor.patch_dim)
    outputs = student_model(csi_patches)
    
    print(f"âœ… å­¦ç”Ÿæ¨¡å‹è¾“å‡º:")
    for key, value in outputs.items():
        if isinstance(value, torch.Tensor):
            print(f"   {key}: {value.shape}")
        elif isinstance(value, list):
            print(f"   {key}: {len(value)}ä¸ªç‰¹å¾")
    
    return teacher_model, student_model, features, outputs


def test_losses(teacher_features, student_outputs):
    """æµ‹è¯•æŸå¤±å‡½æ•°"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æŸå¤±å‡½æ•°")
    print("=" * 50)
    
    from losses import MAELoss, DistillationLoss, ContrastiveLoss, CombinedLoss
    
    batch_size = 2
    
    # æµ‹è¯•MAEæŸå¤±
    print("æµ‹è¯•MAEæŸå¤±...")
    mae_loss_fn = MAELoss()
    
    pred_patches = torch.randn(batch_size, 64, 256)
    target_patches = torch.randn(batch_size, 64, 256)
    mask = torch.randint(0, 2, (batch_size, 64)).bool()
    
    mae_loss = mae_loss_fn(pred_patches, target_patches, mask)
    print(f"âœ… MAEæŸå¤±: {mae_loss.item():.4f}")
    
    # æµ‹è¯•è’¸é¦æŸå¤±
    print("æµ‹è¯•è’¸é¦æŸå¤±...")
    distill_loss_fn = DistillationLoss()
    
    student_features = [torch.randn(batch_size, 65, 384) for _ in range(3)]
    
    distill_loss = distill_loss_fn(student_features, teacher_features)
    print(f"âœ… è’¸é¦æŸå¤±: {distill_loss.item():.4f}")
    
    # æµ‹è¯•å¯¹æ¯”å­¦ä¹ æŸå¤±
    print("æµ‹è¯•å¯¹æ¯”å­¦ä¹ æŸå¤±...")
    contrast_loss_fn = ContrastiveLoss()
    
    anchor_features = torch.randn(batch_size, 256)
    positive_features = torch.randn(batch_size, 256)
    labels = torch.randint(0, 2, (batch_size,))
    
    contrast_loss = contrast_loss_fn(anchor_features, positive_features, labels)
    print(f"âœ… å¯¹æ¯”å­¦ä¹ æŸå¤±: {contrast_loss.item():.4f}")
    
    # æµ‹è¯•ç»„åˆæŸå¤±
    print("æµ‹è¯•ç»„åˆæŸå¤±...")
    combined_loss_fn = CombinedLoss()
    
    skeleton_pred = torch.randn(batch_size, 17, 2)
    skeleton_target = torch.randn(batch_size, 17, 2)
    
    total_loss, loss_dict = combined_loss_fn(
        pred_patches, target_patches, mask,
        skeleton_pred, skeleton_target,
        student_features, teacher_features,
        anchor_features, positive_features, labels
    )
    
    print(f"âœ… ç»„åˆæŸå¤±: {total_loss.item():.4f}")
    print("   å„é¡¹æŸå¤±:")
    for key, value in loss_dict.items():
        print(f"     {key}: {value.item():.4f}")


def test_utils():
    """æµ‹è¯•å·¥å…·å‡½æ•°"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•å·¥å…·å‡½æ•°")
    print("=" * 50)
    
    from utils import (
        LossTracker, calculate_skeleton_metrics,
        get_parameter_count, print_model_info
    )
    
    # æµ‹è¯•æŸå¤±è·Ÿè¸ªå™¨
    print("æµ‹è¯•æŸå¤±è·Ÿè¸ªå™¨...")
    tracker = LossTracker()
    
    for i in range(3):
        loss_dict = {
            'total_loss': torch.tensor(1.0 - i * 0.1),
            'mae_loss': torch.tensor(0.5 - i * 0.05)
        }
        tracker.update(loss_dict)
    
    current_losses = tracker.get_current_losses()
    print(f"âœ… æŸå¤±è·Ÿè¸ª: {current_losses}")
    
    # æµ‹è¯•éª¨éª¼ç‚¹æŒ‡æ ‡
    print("æµ‹è¯•éª¨éª¼ç‚¹æŒ‡æ ‡...")
    pred_skeleton = torch.randn(4, 17, 2)
    target_skeleton = torch.randn(4, 17, 2)
    
    metrics = calculate_skeleton_metrics(pred_skeleton, target_skeleton)
    print(f"âœ… éª¨éª¼ç‚¹æŒ‡æ ‡: MPJPE={metrics['MPJPE']:.4f}")
    
    # æµ‹è¯•å‚æ•°è®¡æ•°
    print("æµ‹è¯•å‚æ•°è®¡æ•°...")
    import torch.nn as nn
    test_model = nn.Sequential(
        nn.Linear(100, 50),
        nn.ReLU(),
        nn.Linear(50, 10)
    )
    
    param_count = get_parameter_count(test_model)
    print(f"âœ… å‚æ•°è®¡æ•°: {param_count}")


def test_integration():
    """é›†æˆæµ‹è¯•"""
    print("\n" + "=" * 50)
    print("é›†æˆæµ‹è¯•")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿå®Œæ•´çš„è®­ç»ƒæ­¥éª¤
    from data_processing import CSIPreprocessor, SkeletonPreprocessor
    from models import TeacherModel, StudentModel
    from losses import CombinedLoss
    
    print("åˆ›å»ºç»„ä»¶...")
    
    # é¢„å¤„ç†å™¨
    csi_preprocessor = CSIPreprocessor(patch_size=8)
    skeleton_preprocessor = SkeletonPreprocessor()
    
    # æ¨¡å‹
    teacher_model = TeacherModel(embed_dim=256, depth=4, num_heads=4)
    student_model = StudentModel(
        num_patches=csi_preprocessor.num_patches,
        patch_dim=csi_preprocessor.patch_dim,
        embed_dim=256,
        depth=4,
        num_heads=4
    )
    
    # æŸå¤±å‡½æ•°
    loss_fn = CombinedLoss()
    
    print("æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤...")
    
    # æ¨¡æ‹Ÿæ•°æ®
    batch_size = 2
    csi_data = torch.randn(batch_size, 3, 30, 297)
    rgb_skeleton = torch.randn(batch_size, 17, 2)
    
    # æ•°æ®é¢„å¤„ç†
    csi_patches, _ = csi_preprocessor(csi_data)
    processed_skeleton = skeleton_preprocessor(rgb_skeleton)
    
    # è€å¸ˆæ¨¡å‹å‰å‘ä¼ æ’­
    teacher_model.eval()
    with torch.no_grad():
        teacher_features = teacher_model.forward_features(processed_skeleton, mask_ratio=0.0)
    
    # å­¦ç”Ÿæ¨¡å‹å‰å‘ä¼ æ’­
    student_model.train()
    student_outputs = student_model(csi_patches)
    
    # è®¡ç®—æŸå¤±
    total_loss, loss_dict = loss_fn(
        student_outputs['reconstructed_patches'], csi_patches, student_outputs['mask'],
        student_outputs['skeleton_pred'], processed_skeleton,
        student_outputs['distill_features'], teacher_features,
        student_outputs['contrast_features'][:1],
        student_outputs['contrast_features'][1:],
        torch.randint(0, 2, (1,))
    )
    
    print(f"âœ… é›†æˆæµ‹è¯•æˆåŠŸ!")
    print(f"   æ€»æŸå¤±: {total_loss.item():.4f}")
    print(f"   é¢„æµ‹éª¨éª¼ç‚¹å½¢çŠ¶: {student_outputs['skeleton_pred'].shape}")
    
    # æ¨¡æ‹Ÿåå‘ä¼ æ’­
    total_loss.backward()
    print("âœ… åå‘ä¼ æ’­æˆåŠŸ!")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹Enhanced Multi-Modal DMAEç»„ä»¶æµ‹è¯•")
    print("=" * 60)
    
    try:
        # æµ‹è¯•å„ä¸ªç»„ä»¶
        csi_preprocessor, skeleton_preprocessor = test_data_processing()
        teacher_model, student_model, teacher_features, student_outputs = test_models(csi_preprocessor)
        test_losses(teacher_features, student_outputs)
        test_utils()
        test_integration()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Enhanced Multi-Modal DMAEç»„ä»¶å·¥ä½œæ­£å¸¸ã€‚")
        print("=" * 60)
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯æ‘˜è¦
        print("\nğŸ“Š æ¨¡å‹ä¿¡æ¯æ‘˜è¦:")
        from utils import get_parameter_count
        
        teacher_params = get_parameter_count(teacher_model)
        student_params = get_parameter_count(student_model)
        
        print(f"è€å¸ˆæ¨¡å‹å‚æ•°: {teacher_params['total_params']:,}")
        print(f"å­¦ç”Ÿæ¨¡å‹å‚æ•°: {student_params['total_params']:,}")
        print(f"æ€»å‚æ•°é‡: {teacher_params['total_params'] + student_params['total_params']:,}")
        
        print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
        print("1. å‡†å¤‡MMFiæ•°æ®é›†")
        print("2. è¿è¡Œ: python example.py demo")
        print("3. å¼€å§‹è®­ç»ƒ: python train.py <dataset_root> <dataset_config>")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)

