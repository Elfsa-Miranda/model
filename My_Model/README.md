# Enhanced Multi-Modal DMAE

å¢å¼ºå‹å¤šæ¨¡æ€DMAEï¼Œç”¨äºCSI-RGBè·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ å’Œé»‘æš—ç¯å¢ƒä¸‹çš„äººä½“å§¿æ€ä¼°è®¡ã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªåˆ›æ–°çš„è·¨æ¨¡æ€å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡WiFi CSIä¿¡å·é¢„æµ‹äººä½“éª¨éª¼ç‚¹ï¼Œç‰¹åˆ«é€‚ç”¨äºé»‘æš—æˆ–éšç§æ•æ„Ÿç¯å¢ƒã€‚

### æ ¸å¿ƒç‰¹æ€§

- **ğŸ« è€å¸ˆ-å­¦ç”Ÿæ¶æ„**: RGBéª¨éª¼ç‚¹è€å¸ˆæ¨¡å‹æŒ‡å¯¼CSIå­¦ç”Ÿæ¨¡å‹
- **ğŸ­ æ©ç è‡ªç¼–ç **: åŸºäºMAEçš„é¢„è®­ç»ƒå’Œé‡å»ºä»»åŠ¡
- **ğŸ”„ çŸ¥è¯†è’¸é¦**: è·¨æ¨¡æ€ç‰¹å¾å¯¹é½å’ŒçŸ¥è¯†è½¬ç§»
- **âš–ï¸ å¯¹æ¯”å­¦ä¹ **: æ­£è´Ÿæ ·æœ¬å¯¹å­¦ä¹ ï¼Œå¢å¼ºè·¨æ¨¡æ€è¡¨ç¤º
- **ğŸŒ™ é»‘æš—æ¨ç†**: ä»…ä½¿ç”¨CSIä¿¡å·è¿›è¡Œäººä½“å§¿æ€ä¼°è®¡

### æŠ€æœ¯æ¶æ„

```
è®­ç»ƒé˜¶æ®µ:
RGBéª¨éª¼ç‚¹ â†’ è€å¸ˆæ¨¡å‹(MAE) â†’ ç‰¹å¾è¡¨ç¤º
CSIæ—¶é¢‘è°± â†’ å­¦ç”Ÿæ¨¡å‹ â†’ é‡å»ºCSI + é¢„æµ‹éª¨éª¼ç‚¹ + ç‰¹å¾è¡¨ç¤º
                    â†“
            ä¸‰é‡æŸå¤±: L_MAE + L_Distill + L_Contrast

æ¨ç†é˜¶æ®µ:
CSIæ—¶é¢‘è°± â†’ å­¦ç”Ÿæ¨¡å‹ â†’ é¢„æµ‹éª¨éª¼ç‚¹
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
My_Model/
â”œâ”€â”€ __init__.py              # åŒ…åˆå§‹åŒ–
â”œâ”€â”€ models.py                # æ¨¡å‹å®šä¹‰ (TeacherModel, StudentModel)
â”œâ”€â”€ losses.py                # æŸå¤±å‡½æ•° (MAE, è’¸é¦, å¯¹æ¯”å­¦ä¹ )
â”œâ”€â”€ data_processing.py       # æ•°æ®é¢„å¤„ç† (CSI, éª¨éª¼ç‚¹)
â”œâ”€â”€ utils.py                 # å·¥å…·å‡½æ•° (è®­ç»ƒ, è¯„ä¼°, å¯è§†åŒ–)
â”œâ”€â”€ train.py                 # è®­ç»ƒæµç¨‹
â”œâ”€â”€ example.py               # ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ config.yaml              # é…ç½®æ–‡ä»¶
â””â”€â”€ README.md               # è¯´æ˜æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
pip install torch torchvision torchaudio
pip install numpy scipy matplotlib pyyaml tqdm
pip install timm  # Transformeræ¨¡å‹åº“

# å¯é€‰: å®‰è£…å…¶ä»–ä¾èµ–
pip install tensorboard wandb  # æ—¥å¿—è®°å½•
```

### 2. æ•°æ®å‡†å¤‡

ç¡®ä¿MMFiæ•°æ®é›†æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç»„ç»‡ï¼š

```
${DATASET_ROOT}/
â”œâ”€â”€ E01/
â”‚   â”œâ”€â”€ S01/
â”‚   â”‚   â”œâ”€â”€ A01/
â”‚   â”‚   â”‚   â”œâ”€â”€ rgb/           # RGBå…³é”®ç‚¹æ•°æ® (.npy)
â”‚   â”‚   â”‚   â”œâ”€â”€ wifi-csi/      # WiFi-CSIæ•°æ® (.mat)
â”‚   â”‚   â”‚   â””â”€â”€ ground_truth.npy
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

### 3. é…ç½®è®¾ç½®

ç¼–è¾‘ `config.yaml` æ–‡ä»¶ï¼Œè°ƒæ•´æ¨¡å‹å’Œè®­ç»ƒå‚æ•°ï¼š

```yaml
# åŸºç¡€è®¾ç½®
seed: 42
output_dir: "./outputs"

# æ¨¡å‹é…ç½®
teacher_model:
  embed_dim: 768
  depth: 12
  num_heads: 12

student_model:
  embed_dim: 768
  depth: 12
  num_heads: 12

# è®­ç»ƒé…ç½®
teacher_pretrain_epochs: 50
student_distill_epochs: 100
```

### 4. æ¨¡å‹è®­ç»ƒ

#### æ–¹æ³•1: ä½¿ç”¨è®­ç»ƒè„šæœ¬

```bash
# å®Œæ•´è®­ç»ƒæµç¨‹
python train.py C:/tangyx/MMFi_Dataset/filtered_mmwave/filtered_mmwave ../MMFi_dataset/config.yaml \
    --config config.yaml \
    --output_dir ./outputs
```

#### æ–¹æ³•2: ä½¿ç”¨ç¤ºä¾‹è„šæœ¬

```bash
# è®­ç»ƒæ¨¡å‹
python example.py train C:/tangyx/MMFi_Dataset/filtered_mmwave/filtered_mmwave ../MMFi_dataset/config.yaml \
    --config config.yaml \
    --output_dir ./outputs
```

### 5. æ¨¡å‹æµ‹è¯•

```bash
# æµ‹è¯•æ¨¡å‹æ€§èƒ½
python example.py test ./outputs/student_checkpoints/best_model.pth \
    C:/tangyx/MMFi_Dataset/filtered_mmwave/filtered_mmwave ../MMFi_dataset/config.yaml \
    --output_dir ./test_results
```

### 6. å•æ ·æœ¬æ¨ç†

```bash
# æ¨ç†å•ä¸ªCSIæ–‡ä»¶
python example.py infer ./outputs/student_checkpoints/best_model.pth \
    /path/to/csi_file.mat \
    --output_dir ./inference_results
```

### 7. æ¼”ç¤ºæ¨¡å¼

```bash
# è¿è¡Œæ¼”ç¤ºï¼Œæµ‹è¯•æ‰€æœ‰ç»„ä»¶
python example.py demo
```

## ğŸ“Š è®­ç»ƒæµç¨‹

### é˜¶æ®µ1: è€å¸ˆæ¨¡å‹é¢„è®­ç»ƒ

- **è¾“å…¥**: RGBéª¨éª¼ç‚¹æ•°æ®
- **ä»»åŠ¡**: æ©ç è‡ªç¼–ç é‡å»º
- **ç›®æ ‡**: å­¦ä¹ éª¨éª¼ç‚¹çš„è¯­ä¹‰è¡¨ç¤º

```python
# è€å¸ˆæ¨¡å‹é¢„è®­ç»ƒ
loss, pred, mask = teacher_model(rgb_skeleton)
```

### é˜¶æ®µ2: å­¦ç”Ÿæ¨¡å‹è’¸é¦è®­ç»ƒ

- **è¾“å…¥**: CSIæ—¶é¢‘è°±æ•°æ®
- **ä»»åŠ¡**: CSIé‡å»º + éª¨éª¼ç‚¹é¢„æµ‹ + çŸ¥è¯†è’¸é¦ + å¯¹æ¯”å­¦ä¹ 
- **ç›®æ ‡**: ä»CSIå­¦ä¹ é¢„æµ‹éª¨éª¼ç‚¹

```python
# å­¦ç”Ÿæ¨¡å‹è®­ç»ƒ
student_outputs = student_model(csi_patches)
total_loss = mae_loss + distill_loss + contrast_loss
```

### æŸå¤±å‡½æ•°ç»„åˆ

```
L_total = L_MAE + Î± * L_Distill + Î² * L_Contrast

å…¶ä¸­:
- L_MAE: CSIé‡å»ºæŸå¤± + éª¨éª¼ç‚¹é¢„æµ‹æŸå¤±
- L_Distill: å­¦ç”Ÿ-è€å¸ˆç‰¹å¾å¯¹é½æŸå¤±
- L_Contrast: æ­£è´Ÿæ ·æœ¬å¯¹å¯¹æ¯”æŸå¤±
- Î±, Î²: æŸå¤±æƒé‡ (é»˜è®¤: Î±=1.0, Î²=0.5)
```

## ğŸ”§ é…ç½®è¯´æ˜

### æ¨¡å‹é…ç½®

```yaml
# è€å¸ˆæ¨¡å‹ (RGBéª¨éª¼ç‚¹MAE)
teacher_model:
  num_joints: 17           # å…³èŠ‚ç‚¹æ•°é‡
  coord_dim: 2             # åæ ‡ç»´åº¦
  embed_dim: 768           # åµŒå…¥ç»´åº¦
  depth: 12                # Transformerå±‚æ•°
  mask_ratio: 0.75         # æ©ç æ¯”ä¾‹

# å­¦ç”Ÿæ¨¡å‹ (CSIå¤šåˆ†æ”¯)
student_model:
  embed_dim: 768           # åµŒå…¥ç»´åº¦
  depth: 12                # Transformerå±‚æ•°
  contrast_dim: 256        # å¯¹æ¯”å­¦ä¹ ç‰¹å¾ç»´åº¦
  mask_ratio: 0.75         # æ©ç æ¯”ä¾‹
```

### æŸå¤±é…ç½®

```yaml
combined_loss:
  mae_weight: 1.0          # MAEæŸå¤±æƒé‡
  distill_weight: 1.0      # è’¸é¦æŸå¤±æƒé‡
  contrast_weight: 0.5     # å¯¹æ¯”å­¦ä¹ æŸå¤±æƒé‡
```

### è®­ç»ƒé…ç½®

```yaml
# è®­ç»ƒepochæ•°
teacher_pretrain_epochs: 50    # è€å¸ˆé¢„è®­ç»ƒ
student_distill_epochs: 100    # å­¦ç”Ÿè’¸é¦è®­ç»ƒ

# ä¼˜åŒ–å™¨
teacher_optimizer:
  type: "adamw"
  lr: 1.0e-4
  weight_decay: 1.0e-2

# å­¦ä¹ ç‡è°ƒåº¦å™¨
teacher_scheduler:
  type: "cosine"
  T_max: 50
```

## ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡

### éª¨éª¼ç‚¹é¢„æµ‹æŒ‡æ ‡

- **MPJPE**: Mean Per Joint Position Error (å¹³å‡å…³èŠ‚ä½ç½®è¯¯å·®)
- **PCK@Î±**: Percentage of Correct Keypoints (æ­£ç¡®å…³é”®ç‚¹ç™¾åˆ†æ¯”)
  - PCK@0.05, PCK@0.1, PCK@0.2, PCK@0.5

### è®­ç»ƒç›‘æ§

- **MAEæŸå¤±**: CSIé‡å»º + éª¨éª¼ç‚¹é¢„æµ‹
- **è’¸é¦æŸå¤±**: ç‰¹å¾å¯¹é½
- **å¯¹æ¯”æŸå¤±**: æ­£è´Ÿæ ·æœ¬å¯¹åŒºåˆ†

## ğŸ¨ å¯è§†åŒ–åŠŸèƒ½

### è®­ç»ƒæ›²çº¿

```python
# è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ›²çº¿
visualize_training_curves(loss_history, save_path)
```

### éª¨éª¼ç‚¹é¢„æµ‹

```python
# å¯è§†åŒ–é¢„æµ‹ç»“æœ
visualize_skeleton_prediction(pred_skeleton, target_skeleton, save_path)
```

### CSIæ—¶é¢‘è°±

```python
# å¯è§†åŒ–CSIæ•°æ®
visualize_csi_data(csi_data, save_path)
```

## ğŸ” ä½¿ç”¨ç¤ºä¾‹

### Python APIä½¿ç”¨

```python
from My_Model import EnhancedDMAEInference

# åˆ›å»ºæ¨ç†å™¨
inference = EnhancedDMAEInference(model_path, config_path)

# é¢„æµ‹éª¨éª¼ç‚¹
skeleton = inference.predict_skeleton(csi_data)

# å¸¦ç½®ä¿¡åº¦é¢„æµ‹
mean_skeleton, std_skeleton = inference.predict_with_confidence(csi_data)
```

### æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡é¢„æµ‹
batch_csi = torch.stack([csi1, csi2, csi3])  # [batch, ...]
batch_skeletons = inference.predict_skeleton(batch_csi)
```

## ğŸ“‹ æ¨¡å‹æ€§èƒ½

### è®¡ç®—å¤æ‚åº¦

- **è€å¸ˆæ¨¡å‹**: ~86M å‚æ•° (ViT-Baseè§„æ¨¡)
- **å­¦ç”Ÿæ¨¡å‹**: ~86M å‚æ•° + å¤šåˆ†æ”¯å¤´
- **æ¨ç†é€Ÿåº¦**: ~10ms/æ ·æœ¬ (GPU)

### å†…å­˜ä½¿ç”¨

- **è®­ç»ƒ**: ~8GB GPUå†…å­˜ (batch_size=32)
- **æ¨ç†**: ~2GB GPUå†…å­˜

## ğŸ› ï¸ é«˜çº§åŠŸèƒ½

### è‡ªå®šä¹‰æ•°æ®é›†

```python
# ç»§æ‰¿å¹¶å®ç°è‡ªå®šä¹‰æ•°æ®é›†
class CustomCSIDataset(Dataset):
    def __init__(self, csi_files, skeleton_files):
        # å®ç°æ•°æ®åŠ è½½é€»è¾‘
        pass
    
    def __getitem__(self, idx):
        # è¿”å› {'csi': csi_data, 'skeleton': skeleton_data}
        pass
```

### æ¨¡å‹å¾®è°ƒ

```python
# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = StudentModel(...)
checkpoint = torch.load('pretrained_model.pth')
model.load_state_dict(checkpoint['model_state_dict'])

# å†»ç»“éƒ¨åˆ†å±‚
for param in model.blocks[:6].parameters():
    param.requires_grad = False

# å¾®è°ƒè®­ç»ƒ
optimizer = torch.optim.AdamW(
    filter(lambda p: p.requires_grad, model.parameters()),
    lr=1e-5
)
```

### åˆ†å¸ƒå¼è®­ç»ƒ

```python
# ä½¿ç”¨DistributedDataParallel
model = nn.parallel.DistributedDataParallel(model)
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   ```yaml
   # å‡å°batch_sizeæˆ–æ¨¡å‹å°ºå¯¸
   train_loader:
     batch_size: 16  # ä»32å‡å°åˆ°16
   ```

2. **æ”¶æ•›ç¼“æ…¢**
   ```yaml
   # è°ƒæ•´å­¦ä¹ ç‡å’Œæƒé‡
   combined_loss:
     distill_weight: 2.0  # å¢åŠ è’¸é¦æŸå¤±æƒé‡
   ```

3. **é¢„æµ‹ç²¾åº¦ä½**
   ```yaml
   # å¢åŠ è®­ç»ƒepochæˆ–è°ƒæ•´æ©ç æ¯”ä¾‹
   student_distill_epochs: 200
   student_model:
     mask_ratio: 0.5  # é™ä½æ©ç æ¯”ä¾‹
   ```

### è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
python train.py --debug --log_level DEBUG
```

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **MAE**: Masked Autoencoders Are Scalable Vision Learners
2. **DMAE**: Distilled Masked Autoencoders
3. **SimCLR**: A Simple Framework for Contrastive Learning
4. **MMFi**: Multi-Modal Human Activity Recognition

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ“ è”ç³»æ–¹å¼

- é¡¹ç›®é“¾æ¥: [https://github.com/your-username/enhanced-dmae](https://github.com/your-username/enhanced-dmae)
- é—®é¢˜åé¦ˆ: [Issues](https://github.com/your-username/enhanced-dmae/issues)

---

**æ³¨æ„**: æœ¬é¡¹ç›®ä»…ç”¨äºç ”ç©¶ç›®çš„ï¼Œè¯·éµå®ˆç›¸å…³æ•°æ®ä½¿ç”¨åè®®å’Œéšç§ä¿æŠ¤è§„å®šã€‚
